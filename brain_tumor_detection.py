# -*- coding: utf-8 -*-
"""Brain_Tumor_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/109dH9PIoD2Hd7gmzbWt00XO7VrZTuPMX
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

###comment
#train_loss=history.history['loss']
#val_loss=history.history['val_loss']
#sx=range(6)
#plt.figure(1,figsize=(7,5))
#plt.plot(sx,train_loss)
#plt.plot(sx,val_loss)
#plt.xlabel("No. of epochs")
#plt.ylabel("Loss")
#plt.title("Train_loss vs val_loss")
#plt.grid(True)
#plt.legend(['Train','Val'])

"""**Mount Drive**"""

from google.colab import drive
drive.mount('/content/drive')

"""**Collect data**"""

import os
path = os.listdir('/content/drive/MyDrive/brain_tumor/Training/')
classes = {'no_tumor':0, 'pituitary_tumor':1}

import cv2
X = []
Y = []
for cls in classes:
    pth = '/content/drive/MyDrive/brain_tumor/Training/'+cls
    for j in os.listdir(pth):
        img = cv2.imread(pth+'/'+j, 0)
        img = cv2.resize(img, (180,180))
        X.append(img)
        Y.append(classes[cls])

"""**Data Analysis**"""

X = np.array(X)
Y = np.array(Y)

X_updated = X.reshape(len(X), -1)

np.unique(Y)

pd.Series(Y).value_counts()

X.shape, X_updated.shape

"""**Data  Visualization**"""

plt.imshow(X[0], cmap='gray')

X_updated = X.reshape(len(X), -1)
X_updated.shape

"""**Split Data**"""

xtrain, xtest, ytrain, ytest = train_test_split(X_updated, Y, random_state=10,
                                               test_size=.20)

xtrain.shape, xtest.shape

"""**Feature Scalling**"""

print(xtrain.max(), xtrain.min())
print(xtest.max(), xtest.min())
xtrain = xtrain/255
xtest = xtest/255
print(xtrain.max(), xtrain.min())
print(xtest.max(), xtest.min())

"""**Feature Selection**"""

from sklearn.decomposition import PCA

print(xtrain.shape, xtest.shape)

pca = PCA(.98)
# pca_train = pca.fit_transform(xtrain)
# pca_test = pca.transform(xtest)
pca_train = xtrain
pca_test = xtest

"""**Model Training**

**SVM**
"""

from sklearn.svm import SVC

sv = SVC()
sv.fit(xtrain, ytrain)

print("Training Score:", sv.score(xtrain, ytrain))
print("Testing Score:", sv.score(xtest, ytest))

pred = sv.predict(xtest)

misclassified=np.where(ytest!=pred)
misclassified

print("Total Misclassified Samples: ",len(misclassified[0]))
print(pred[58],ytest[58])

print("Accuracy for svm:",accuracy_score(ytest,pred))

confusion_matrix(ytest,pred)

print(classification_report(ytest,pred))

"""**Logistic Regression**"""

from sklearn.linear_model import LogisticRegression

import warnings
warnings.filterwarnings('ignore')

lg = LogisticRegression(C=0.1)
lg.fit(xtrain, ytrain)

print("Training Score:", lg.score(xtrain, ytrain))
print("Testing Score:", lg.score(xtest, ytest))

pred2=lg.predict(xtest)

misclassified=np.where(ytest!=pred)
misclassified

print("Total Misclassified Samples: ",len(misclassified[0]))
print(pred2[58],ytest[58])

print("Accuracy for logistic:",accuracy_score(ytest,pred2))

confusion_matrix(ytest,pred2)

print(classification_report(ytest,pred2))

"""**CNN**"""

import keras
import os
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from sklearn.preprocessing import OneHotEncoder
from PIL import Image

encoder = OneHotEncoder()
encoder.fit([[0], [1]])

data = []
paths = []
result = []

for r, d, f in os.walk(r'../content/drive/MyDrive/brain_tumor/Training/pituitary_tumor'):
    for file in f:
        if '.jpg' in file:
            paths.append(os.path.join(r, file))

for path in paths:
    img = Image.open(path)
    img = img.resize((128,128))
    img = np.array(img)
    if(img.shape == (128,128,3)):
        data.append(np.array(img))
        result.append(encoder.transform([[1]]).toarray())

paths = []
for r, d, f in os.walk(r"../content/drive/MyDrive/brain_tumor/Training/no_tumor"):
    for file in f:
        if '.jpg' in file:
            paths.append(os.path.join(r, file))

for path in paths:
    img = Image.open(path)
    img = img.resize((128,128))
    img = np.array(img)
    if(img.shape == (128,128,3)):
        data.append(np.array(img))
        result.append(encoder.transform([[0]]).toarray())

data = np.array(data)
data.shape

result = np.array(result)
result = result.reshape(1222,2)
result.shape

x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=result, random_state=0)

model = Sequential()

model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding = 'Same'))
model.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))


model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))
model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))
model.add(Dropout(0.25))

model.add(Flatten())

model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))

model.compile(loss = "categorical_crossentropy", optimizer='Adamax',metrics=['accuracy'])
print(model.summary())

y_train.shape

x_train.shape

history = model.fit(x_train, y_train, epochs = 30, batch_size = 40, verbose = 1,validation_data = (x_test, y_test))

h=history.history
plt.plot(h['accuracy'])
plt.plot(h['val_accuracy'],c="red")

pred3=model.predict(x_test)

pred3=np.argmax(pred3,axis=1)
y_test=np.argmax(y_test,axis=1)

print("Accuracy for CNN:",accuracy_score(y_test,pred3))

confusion_matrix(y_test,pred3)

y_test.shape

x_test.shape

print(classification_report(y_test,pred3))

"""**Testing**

**SVM Model test**
"""

dec = {0:'No Tumor', 1:'Positive Tumor'}

plt.figure(figsize=(12,8))
p = os.listdir('/content/drive/MyDrive/brain_tumor/Testing/')
c=1
for i in os.listdir('/content/drive/MyDrive/brain_tumor/Testing/no_tumor/')[:9]:
    plt.subplot(3,3,c)

    img = cv2.imread('/content/drive/MyDrive/brain_tumor/Testing/no_tumor/'+i,0)
    img1 = cv2.resize(img, (180,180))
    img1 = img1.reshape(1,-1)/255
    p = sv.predict(img1)
    plt.title(dec[p[0]])
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    c+=1

plt.figure(figsize=(12,8))
p = os.listdir('/content/drive/MyDrive/brain_tumor/Testing')
c=1
for i in os.listdir('/content/drive/MyDrive/brain_tumor/Testing/pituitary_tumor/')[30:46]:
    plt.subplot(4,4,c)

    img = cv2.imread('/content/drive/MyDrive/brain_tumor/Testing/pituitary_tumor/'+i,0)
    img1 = cv2.resize(img, (180,180))
    img1 = img1.reshape(1,-1)/255
    p = sv.predict(img1)
    plt.title(dec[p[0]])
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    c+=1

"""**Logistic Regression Model Test**"""

plt.figure(figsize=(12,8))
p = os.listdir('/content/drive/MyDrive/brain_tumor/Testing')
c=1
for i in os.listdir('/content/drive/MyDrive/brain_tumor/Testing/pituitary_tumor/')[30:46]:
    plt.subplot(4,4,c)

    img = cv2.imread('/content/drive/MyDrive/brain_tumor/Testing/pituitary_tumor/'+i,0)
    img1 = cv2.resize(img, (180,180))
    img1 = img1.reshape(1,-1)/255
    p = lg.predict(img1)
    plt.title(dec[p[0]])
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    c+=1



"""CNN Model Test"""

dec = {0:'No Tumor', 1:'Positive Tumor'}

def names(number):
    if number==1:
        return 'Its a Tumor'
    else:
        return 'No, Its not a tumor'

from matplotlib.pyplot import imshow
img = Image.open(r"/content/drive/MyDrive/brain_tumor/Testing/pituitary_tumor/image(19).jpg")
x = np.array(img.resize((128,128)))
x = x.reshape(1,128,128,3)
pred4 = model.predict_on_batch(x)
classification = np.where(pred4 == np.amax(pred4))[1][0]
imshow(img)
print(str(pred4[0][classification]*100) + '% Confidence This Is ' + names(classification))

